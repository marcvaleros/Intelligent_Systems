{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZcv4vg7Tr0U"
      },
      "source": [
        "## UNDERSTANDING DEEP LEARNING REQUIRES RE-THINKING GENERALIZATION\n",
        "\n",
        "SOURCE: https://arxiv.org/pdf/1611.03530.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "awTg-UgMTr0e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8IO35089Tr0h"
      },
      "outputs": [],
      "source": [
        "input_channels = 3\n",
        "num_classes = 10\n",
        "\n",
        "device = 'cuda'\n",
        "lr = 0.01\n",
        "epochs = 32\n",
        "batch_size = 80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlM8roZgTr0i"
      },
      "source": [
        "### Dataset - CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yMORsbErTr0j"
      },
      "outputs": [],
      "source": [
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # convert image to tensor\n",
        "    transforms.CenterCrop(28) # crop from the center\n",
        "])\n",
        "\n",
        "def norm_image(data_sample):\n",
        "    img_tensor = data_sample[0] # image tensors\n",
        "    label = data_sample[1]\n",
        "\n",
        "    img_means = img_tensor.mean(axis=[1,2]) # mean of image per channel\n",
        "    img_sds = img_tensor.std(axis=[1,2]) # overall SD of image per channel\n",
        "\n",
        "    mean_sub = img_tensor - img_means.unsqueeze(1).unsqueeze(2)\n",
        "    img_norm = mean_sub.true_divide(img_sds.unsqueeze(1).unsqueeze(2))\n",
        "\n",
        "    return (img_norm, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and Testing Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzvvEA-nTr0j",
        "outputId": "7a935f76-babd-4281-8a3f-8bf9b15f1aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# training set\n",
        "\n",
        "all_train = list(datasets.CIFAR10(root = 'data/', transform=img_transform, train = True, download=True))\n",
        "\n",
        "random.shuffle(all_train)\n",
        "\n",
        "train_data = all_train[:40000]\n",
        "train_transformed = list(map(norm_image, train_data))\n",
        "train_loader = DataLoader(dataset=train_transformed, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_data = all_train[40000:]\n",
        "val_transformed = list(map(norm_image, val_data))\n",
        "val_loader = DataLoader(dataset=val_transformed, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_data = datasets.CIFAR10(root='data/', transform=img_transform, train=False, download=True)\n",
        "test_transformed = list(map(norm_image, val_data))\n",
        "test_loader = DataLoader(dataset=val_transformed, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzV2W-sATr0v"
      },
      "source": [
        "## Implementation of Reduced GoogLeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ffb2hjuATr0w"
      },
      "outputs": [],
      "source": [
        "class conv_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(conv_block, self).__init__()\n",
        "        self.relu = nn.ReLU() # ReLU\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs) # convolution\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) # batch normalization\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class inception_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_ch1, out_ch3):\n",
        "        super(inception_block, self).__init__()\n",
        "        # first conv module, same padding\n",
        "        self.ch1 = conv_block(in_channels=in_channels, out_channels=out_ch1, kernel_size=(3,3), stride=(1,1), padding='same')\n",
        "        # second conv module, same padding\n",
        "        self.ch3 = conv_block(in_channels=in_channels, out_channels=out_ch3, kernel_size=(3,3), stride=(1,1), padding='same')\n",
        "\n",
        "    def forward(self,x):\n",
        "        # concatenate convolution outputs\n",
        "        return torch.cat([self.ch1(x),self.ch3(x)],1)\n",
        "\n",
        "class downsample_block(nn.Module):\n",
        "    def __init__(self, in_channels, conv_out):\n",
        "        super(downsample_block, self).__init__()\n",
        "        # conv module\n",
        "        self.convblock = conv_block(in_channels, conv_out, kernel_size=(3,3), stride=(2,2))\n",
        "        # max pooling\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2))\n",
        "\n",
        "    def forward(self,x):\n",
        "        return torch.cat([self.convblock(x),self.maxpool(x)],1)\n",
        "\n",
        "class mini_GoogLeNet(nn.Module):\n",
        "    def __init__(self,in_channels=3, num_classes=10, dropout_prob=0):\n",
        "        super(mini_GoogLeNet, self).__init__()\n",
        "        self.conv1 = conv_block(in_channels=3, out_channels=96, kernel_size=(3,3), stride=(1,1))\n",
        "        self.inception1 = inception_block(96,32,32)\n",
        "        self.inception2 = inception_block(64,32,48)\n",
        "\n",
        "        self.downsample1 = downsample_block(80,80)\n",
        "        self.inception3 = inception_block(160,112,48)\n",
        "        self.inception4 = inception_block(160,96,64)\n",
        "        self.inception5 = inception_block(160,80,80)\n",
        "        self.inception6 = inception_block(160,48,96)\n",
        "\n",
        "        self.downsample2 = downsample_block(144,96)\n",
        "        self.inception7 = inception_block(240,176,160)\n",
        "        self.inception8 = inception_block(336,176,160)\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=(7,7), padding=(1,1))\n",
        "        self.dropout = nn.Dropout(p = dropout_prob)\n",
        "        self.fc = nn.Linear(336,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.inception1(x)\n",
        "        x = self.inception2(x)\n",
        "        x = self.downsample1(x)\n",
        "        x = self.inception3(x)\n",
        "        x = self.inception4(x)\n",
        "        x = self.inception5(x)\n",
        "        x = self.inception6(x)\n",
        "        x = self.downsample2(x)\n",
        "        x = self.inception7(x)\n",
        "        x = self.inception8(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0],-1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46dzdgGcTr0w"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FFbQC9KVTr0x"
      },
      "outputs": [],
      "source": [
        "model = mini_GoogLeNet(in_channels=3, num_classes=10, dropout_prob=0).to(device=device)\n",
        "\n",
        "# parameter settings\n",
        "loss_function = nn.CrossEntropyLoss() # loss funtion\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr) # optimizer\n",
        "scheduler = optim.lr_scheduler.LinearLR(optimizer) # scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize results\n",
        "train_acc = []\n",
        "train_all_loss = []\n",
        "\n",
        "test_acc = []\n",
        "test_all_loss = []\n",
        "\n",
        "con_mats = []\n",
        "\n",
        "times = []\n",
        "train_times = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Zc9jlRd2Tr0x"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    curr_loss_train = 0 # loss\n",
        "    correct_train = 0 # correctly classified training points\n",
        "    total_train = 0 # total number of training points\n",
        "\n",
        "    for ind, (data_train, true_labels_train) in enumerate(train_loader):\n",
        "        data_train = data_train.to(device=device) # use GPU\n",
        "        true_labels_train = true_labels_train.to(device=device) # use GPU\n",
        "\n",
        "        out_train = model(data_train) # apply model to training data\n",
        "        loss_train = loss_function(out_train, true_labels_train) # get loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        curr_loss_train += loss_train.item()\n",
        "        ix, predicted_train = out_train.max(1)\n",
        "        correct_train += predicted_train.eq(true_labels_train).sum().item()\n",
        "        total_train += true_labels_train.size(0)\n",
        "\n",
        "    train_loss = curr_loss_train/len(train_loader) # get loss\n",
        "    acc_train_val = (correct_train/total_train)*100 # get accuracy\n",
        "\n",
        "    train_acc.append(acc_train_val)\n",
        "    train_all_loss.append(train_loss)\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    curr_loss_test = 0 # loss\n",
        "    correct_test = 0 # correctly classified test points\n",
        "    total_test = 0 # total number of test points\n",
        "    num_class = 10\n",
        "    confusion_matrix = torch.zeros(num_class, num_class)\n",
        "    with torch.no_grad():\n",
        "        for data_test, true_labels_test in test_loader:\n",
        "\n",
        "            data_test = data_test.to(device=device) # use GPU\n",
        "            true_labels_test = true_labels_test.to(device=device) # use GPU\n",
        "\n",
        "            out_test = model(data_test) # apply model to training data\n",
        "            loss_test = loss_function(out_test, true_labels_test) # get loss\n",
        "\n",
        "            # metrics\n",
        "            curr_loss_test += loss_test.item()\n",
        "            ix, predicted_test = out_test.max(1)\n",
        "            correct_test += predicted_test.eq(true_labels_test).sum().item()\n",
        "            total_test += true_labels_test.size(0)\n",
        "\n",
        "\n",
        "    test_loss = curr_loss_test/len(test_loader) # get loss\n",
        "    acc_test_val = (correct_test/total_test)*100 # get accuracy\n",
        "\n",
        "    test_acc.append(acc_test_val)\n",
        "    test_all_loss.append(test_loss)\n",
        "    con_mats.append(confusion_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjF4y3LATr0y",
        "outputId": "b110d843-81f6-45be-c2f6-b43b78753866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time: 276.80 seconds\n",
            "Epoch 1\n",
            "Epoch time: 276.68 seconds\n",
            "Epoch 2\n",
            "Epoch time: 276.85 seconds\n",
            "Epoch 3\n",
            "Epoch time: 277.27 seconds\n",
            "Epoch 4\n",
            "Epoch time: 276.66 seconds\n",
            "Epoch 5\n",
            "Epoch time: 276.25 seconds\n",
            "Epoch 6\n",
            "Epoch time: 276.35 seconds\n",
            "Epoch 7\n",
            "Epoch time: 279.91 seconds\n",
            "Epoch 8\n",
            "Epoch time: 276.48 seconds\n",
            "Epoch 9\n",
            "Epoch time: 276.45 seconds\n",
            "Epoch 10\n",
            "Epoch time: 276.61 seconds\n",
            "Epoch 11\n",
            "Epoch time: 276.43 seconds\n",
            "Epoch 12\n",
            "Epoch time: 276.40 seconds\n",
            "Epoch 13\n",
            "Epoch time: 276.38 seconds\n",
            "Epoch 14\n",
            "Epoch time: 276.46 seconds\n",
            "Epoch 15\n",
            "Epoch time: 276.45 seconds\n",
            "Epoch 16\n",
            "Epoch time: 276.48 seconds\n",
            "Epoch 17\n",
            "Epoch time: 276.43 seconds\n",
            "Epoch 18\n",
            "Epoch time: 276.45 seconds\n",
            "Epoch 19\n",
            "Epoch time: 276.43 seconds\n",
            "Epoch 20\n",
            "Epoch time: 276.48 seconds\n",
            "Epoch 21\n",
            "Epoch time: 276.43 seconds\n",
            "Epoch 22\n",
            "Epoch time: 276.46 seconds\n",
            "Epoch 23\n",
            "Epoch time: 276.44 seconds\n",
            "Epoch 24\n",
            "Epoch time: 276.44 seconds\n",
            "Epoch 25\n",
            "Epoch time: 276.44 seconds\n",
            "Epoch 26\n",
            "Epoch time: 276.48 seconds\n",
            "Epoch 27\n",
            "Epoch time: 276.42 seconds\n",
            "Epoch 28\n",
            "Epoch time: 276.46 seconds\n",
            "Epoch 29\n",
            "Epoch time: 276.43 seconds\n",
            "Epoch 30\n",
            "Epoch time: 276.51 seconds\n",
            "Epoch 31\n",
            "Epoch time: 276.46 seconds\n",
            "\n",
            "Total training time: 8851.71 seconds\n"
          ]
        }
      ],
      "source": [
        "train_start = time.time()\n",
        "for epoch in range(epochs):\n",
        "    ep_start = time.time()\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()\n",
        "\n",
        "    epoch_time = time.time() - ep_start\n",
        "    print(f\"Epoch time: {epoch_time:0.2f} seconds\")\n",
        "    times.append(epoch_time)\n",
        "\n",
        "    train_time = time.time() - train_start\n",
        "    train_times.append(train_time)\n",
        "\n",
        "print()\n",
        "print(f\"Total training time: {train_time:0.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e0AQ1ahTr0y"
      },
      "source": [
        "## Export results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "owKPEEyrTr0y"
      },
      "outputs": [],
      "source": [
        "df_res = pd.DataFrame()\n",
        "df_res['TrainAccuracy'] = train_acc\n",
        "df_res['TrainLoss'] = train_all_loss\n",
        "df_res['TestAccuracy'] = test_acc\n",
        "df_res['TestLoss'] = test_all_loss\n",
        "df_res['EpochTime'] = times\n",
        "df_res['Totaltime'] = train_times\n",
        "\n",
        "df_res.to_csv('19-results.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "u5vL6_pYTr0z"
      },
      "outputs": [],
      "source": [
        "with open('19-confusion_matrices.pickle','wb') as handle:\n",
        "    pickle.dump(con_mats, handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIID2g15Tr0z"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SPcL-nk6Tr0z",
        "outputId": "fbde4e32-bf2f-4b4a-9731-f04c43a74ed4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TrainAccuracy</th>\n",
              "      <th>TrainLoss</th>\n",
              "      <th>TestAccuracy</th>\n",
              "      <th>TestLoss</th>\n",
              "      <th>EpochTime</th>\n",
              "      <th>Totaltime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31.0875</td>\n",
              "      <td>2.033667</td>\n",
              "      <td>39.02</td>\n",
              "      <td>1.767887</td>\n",
              "      <td>276.802399</td>\n",
              "      <td>276.803397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47.4500</td>\n",
              "      <td>1.555674</td>\n",
              "      <td>51.91</td>\n",
              "      <td>1.415237</td>\n",
              "      <td>276.683578</td>\n",
              "      <td>553.486975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>57.6700</td>\n",
              "      <td>1.248891</td>\n",
              "      <td>53.47</td>\n",
              "      <td>1.345573</td>\n",
              "      <td>276.845322</td>\n",
              "      <td>830.332296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>64.2925</td>\n",
              "      <td>1.049838</td>\n",
              "      <td>63.83</td>\n",
              "      <td>1.042297</td>\n",
              "      <td>277.266675</td>\n",
              "      <td>1107.599968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69.4450</td>\n",
              "      <td>0.897086</td>\n",
              "      <td>60.72</td>\n",
              "      <td>1.169229</td>\n",
              "      <td>276.662290</td>\n",
              "      <td>1384.262258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>73.6975</td>\n",
              "      <td>0.779820</td>\n",
              "      <td>59.11</td>\n",
              "      <td>1.245290</td>\n",
              "      <td>276.246786</td>\n",
              "      <td>1660.509044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>78.0550</td>\n",
              "      <td>0.660093</td>\n",
              "      <td>69.55</td>\n",
              "      <td>0.866342</td>\n",
              "      <td>276.353543</td>\n",
              "      <td>1936.862586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>81.5425</td>\n",
              "      <td>0.558322</td>\n",
              "      <td>72.21</td>\n",
              "      <td>0.828857</td>\n",
              "      <td>279.914706</td>\n",
              "      <td>2216.777292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>84.3575</td>\n",
              "      <td>0.480229</td>\n",
              "      <td>61.96</td>\n",
              "      <td>1.205901</td>\n",
              "      <td>276.479648</td>\n",
              "      <td>2493.256940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>87.3425</td>\n",
              "      <td>0.397234</td>\n",
              "      <td>67.57</td>\n",
              "      <td>0.999281</td>\n",
              "      <td>276.447989</td>\n",
              "      <td>2769.704929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>89.8950</td>\n",
              "      <td>0.324824</td>\n",
              "      <td>66.70</td>\n",
              "      <td>1.064341</td>\n",
              "      <td>276.612980</td>\n",
              "      <td>3046.317908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>92.4125</td>\n",
              "      <td>0.252772</td>\n",
              "      <td>70.50</td>\n",
              "      <td>0.928623</td>\n",
              "      <td>276.433074</td>\n",
              "      <td>3322.750983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>94.8600</td>\n",
              "      <td>0.185237</td>\n",
              "      <td>70.56</td>\n",
              "      <td>1.026493</td>\n",
              "      <td>276.396858</td>\n",
              "      <td>3599.147841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>96.7100</td>\n",
              "      <td>0.133243</td>\n",
              "      <td>75.75</td>\n",
              "      <td>0.787235</td>\n",
              "      <td>276.381198</td>\n",
              "      <td>3875.529039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>98.1300</td>\n",
              "      <td>0.088024</td>\n",
              "      <td>77.41</td>\n",
              "      <td>0.712141</td>\n",
              "      <td>276.464600</td>\n",
              "      <td>4151.993639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>99.1100</td>\n",
              "      <td>0.054721</td>\n",
              "      <td>78.97</td>\n",
              "      <td>0.686067</td>\n",
              "      <td>276.448533</td>\n",
              "      <td>4428.442172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>99.7275</td>\n",
              "      <td>0.030156</td>\n",
              "      <td>78.43</td>\n",
              "      <td>0.721295</td>\n",
              "      <td>276.480254</td>\n",
              "      <td>4704.922426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>99.9500</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>81.04</td>\n",
              "      <td>0.629952</td>\n",
              "      <td>276.431129</td>\n",
              "      <td>4981.353555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>99.9775</td>\n",
              "      <td>0.011809</td>\n",
              "      <td>80.85</td>\n",
              "      <td>0.642773</td>\n",
              "      <td>276.447603</td>\n",
              "      <td>5257.801158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>99.9925</td>\n",
              "      <td>0.008769</td>\n",
              "      <td>81.44</td>\n",
              "      <td>0.621008</td>\n",
              "      <td>276.431332</td>\n",
              "      <td>5534.232490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>99.9975</td>\n",
              "      <td>0.006807</td>\n",
              "      <td>81.43</td>\n",
              "      <td>0.612845</td>\n",
              "      <td>276.480000</td>\n",
              "      <td>5810.712490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>100.0000</td>\n",
              "      <td>0.005569</td>\n",
              "      <td>81.49</td>\n",
              "      <td>0.623286</td>\n",
              "      <td>276.432411</td>\n",
              "      <td>6087.144902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>100.0000</td>\n",
              "      <td>0.005078</td>\n",
              "      <td>81.47</td>\n",
              "      <td>0.626550</td>\n",
              "      <td>276.464434</td>\n",
              "      <td>6363.609335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>100.0000</td>\n",
              "      <td>0.004216</td>\n",
              "      <td>81.58</td>\n",
              "      <td>0.629454</td>\n",
              "      <td>276.438809</td>\n",
              "      <td>6640.049143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>100.0000</td>\n",
              "      <td>0.004145</td>\n",
              "      <td>80.89</td>\n",
              "      <td>0.652674</td>\n",
              "      <td>276.439200</td>\n",
              "      <td>6916.488343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>100.0000</td>\n",
              "      <td>0.003772</td>\n",
              "      <td>81.43</td>\n",
              "      <td>0.633291</td>\n",
              "      <td>276.442719</td>\n",
              "      <td>7192.932061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>100.0000</td>\n",
              "      <td>0.003423</td>\n",
              "      <td>81.41</td>\n",
              "      <td>0.629731</td>\n",
              "      <td>276.479148</td>\n",
              "      <td>7469.412251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>99.9975</td>\n",
              "      <td>0.003519</td>\n",
              "      <td>81.42</td>\n",
              "      <td>0.635349</td>\n",
              "      <td>276.419398</td>\n",
              "      <td>7745.831648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>99.9975</td>\n",
              "      <td>0.002914</td>\n",
              "      <td>81.21</td>\n",
              "      <td>0.640125</td>\n",
              "      <td>276.463429</td>\n",
              "      <td>8022.296014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>100.0000</td>\n",
              "      <td>0.002709</td>\n",
              "      <td>81.26</td>\n",
              "      <td>0.649832</td>\n",
              "      <td>276.430985</td>\n",
              "      <td>8298.727000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>100.0000</td>\n",
              "      <td>0.002752</td>\n",
              "      <td>81.42</td>\n",
              "      <td>0.645413</td>\n",
              "      <td>276.514756</td>\n",
              "      <td>8575.241755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>100.0000</td>\n",
              "      <td>0.002453</td>\n",
              "      <td>81.21</td>\n",
              "      <td>0.657821</td>\n",
              "      <td>276.464118</td>\n",
              "      <td>8851.705873</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    TrainAccuracy  TrainLoss  TestAccuracy  TestLoss   EpochTime    Totaltime\n",
              "0         31.0875   2.033667         39.02  1.767887  276.802399   276.803397\n",
              "1         47.4500   1.555674         51.91  1.415237  276.683578   553.486975\n",
              "2         57.6700   1.248891         53.47  1.345573  276.845322   830.332296\n",
              "3         64.2925   1.049838         63.83  1.042297  277.266675  1107.599968\n",
              "4         69.4450   0.897086         60.72  1.169229  276.662290  1384.262258\n",
              "5         73.6975   0.779820         59.11  1.245290  276.246786  1660.509044\n",
              "6         78.0550   0.660093         69.55  0.866342  276.353543  1936.862586\n",
              "7         81.5425   0.558322         72.21  0.828857  279.914706  2216.777292\n",
              "8         84.3575   0.480229         61.96  1.205901  276.479648  2493.256940\n",
              "9         87.3425   0.397234         67.57  0.999281  276.447989  2769.704929\n",
              "10        89.8950   0.324824         66.70  1.064341  276.612980  3046.317908\n",
              "11        92.4125   0.252772         70.50  0.928623  276.433074  3322.750983\n",
              "12        94.8600   0.185237         70.56  1.026493  276.396858  3599.147841\n",
              "13        96.7100   0.133243         75.75  0.787235  276.381198  3875.529039\n",
              "14        98.1300   0.088024         77.41  0.712141  276.464600  4151.993639\n",
              "15        99.1100   0.054721         78.97  0.686067  276.448533  4428.442172\n",
              "16        99.7275   0.030156         78.43  0.721295  276.480254  4704.922426\n",
              "17        99.9500   0.017606         81.04  0.629952  276.431129  4981.353555\n",
              "18        99.9775   0.011809         80.85  0.642773  276.447603  5257.801158\n",
              "19        99.9925   0.008769         81.44  0.621008  276.431332  5534.232490\n",
              "20        99.9975   0.006807         81.43  0.612845  276.480000  5810.712490\n",
              "21       100.0000   0.005569         81.49  0.623286  276.432411  6087.144902\n",
              "22       100.0000   0.005078         81.47  0.626550  276.464434  6363.609335\n",
              "23       100.0000   0.004216         81.58  0.629454  276.438809  6640.049143\n",
              "24       100.0000   0.004145         80.89  0.652674  276.439200  6916.488343\n",
              "25       100.0000   0.003772         81.43  0.633291  276.442719  7192.932061\n",
              "26       100.0000   0.003423         81.41  0.629731  276.479148  7469.412251\n",
              "27        99.9975   0.003519         81.42  0.635349  276.419398  7745.831648\n",
              "28        99.9975   0.002914         81.21  0.640125  276.463429  8022.296014\n",
              "29       100.0000   0.002709         81.26  0.649832  276.430985  8298.727000\n",
              "30       100.0000   0.002752         81.42  0.645413  276.514756  8575.241755\n",
              "31       100.0000   0.002453         81.21  0.657821  276.464118  8851.705873"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "df_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K-r5RE5kOft"
      },
      "source": [
        "### Best Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHGK9EWrjvvx",
        "outputId": "7abd03ac-dfec-4552-c65d-adcf3fe5fe35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max Accuracy: 81.58%\n"
          ]
        }
      ],
      "source": [
        "max_accuracy = df_res['TestAccuracy'].max()\n",
        "print(f\"Max Accuracy: {max_accuracy}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
