{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "# Load spaCy's English NLP model\n",
    "# do this before running\n",
    "# python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents  = [\n",
    "    \"Game development has progressed over the years due to the advancement in various field of technology.\",\n",
    "    \"Natural language processing is a subfield of artificial intelligence.\",\n",
    "    \"Latent Dirichlet Allocation is a generative probabilistic model.\",\n",
    "    \"Gensim is a popular Python library for topic modeling and document similarity.\",\n",
    "    \"Python is a high level programming language and beginner friendly.\"\n",
    "    \"Valorant is a popular FPS game which is owned by RIOT and it has a nice game interface and amazing maps with various bomb sites\",\n",
    "    \"How big would you dream if you knew you couldn't fail.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Tokenize and lemmatize using spaCy\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to all documents\n",
    "processed_documents = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(processed_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_documents]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model_3 = gensim.models.LdaModel(corpus, num_topics=3, id2word=dictionary, passes=15)\n",
    "\n",
    "lda_model_6 = gensim.models.LdaModel(corpus, num_topics=6, id2word=dictionary, passes=15)\n",
    "\n",
    "lda_model_9 = gensim.models.LdaModel(corpus, num_topics=9, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print topics and their keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model 3 topics\n",
      "[(0,\n",
      "  '0.063*\"language\" + 0.062*\"processing\" + 0.062*\"intelligence\" + '\n",
      "  '0.062*\"artificial\" + 0.062*\"natural\" + 0.062*\"subfield\" + '\n",
      "  '0.016*\"Allocation\" + 0.016*\"Latent\" + 0.016*\"generative\" + '\n",
      "  '0.016*\"probabilistic\"'),\n",
      " (1,\n",
      "  '0.059*\"game\" + 0.041*\"popular\" + 0.041*\"Python\" + 0.024*\"amazing\" + '\n",
      "  '0.024*\"RIOT\" + 0.024*\"level\" + 0.024*\"bomb\" + 0.024*\"programming\" + '\n",
      "  '0.024*\"own\" + 0.024*\"high\"'),\n",
      " (2,\n",
      "  '0.069*\"know\" + 0.069*\"fail\" + 0.069*\"dream\" + 0.069*\"big\" + '\n",
      "  '0.017*\"language\" + 0.017*\"Python\" + 0.017*\"game\" + 0.017*\"generative\" + '\n",
      "  '0.017*\"Latent\" + 0.017*\"Allocation\"')]\n"
     ]
    }
   ],
   "source": [
    "print('LDA Model 3 topics')\n",
    "pprint(lda_model_3.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model 6 topics\n",
      "[(0,\n",
      "  '0.091*\"game\" + 0.034*\"bomb\" + 0.034*\"site\" + 0.034*\"map\" + 0.034*\"amazing\" '\n",
      "  '+ 0.034*\"own\" + 0.034*\"level\" + 0.034*\"interface\" + 0.034*\"beginner\" + '\n",
      "  '0.034*\"friendly\"'),\n",
      " (1,\n",
      "  '0.085*\"language\" + 0.085*\"artificial\" + 0.085*\"processing\" + '\n",
      "  '0.085*\"subfield\" + 0.085*\"intelligence\" + 0.085*\"natural\" + 0.012*\"dream\" + '\n",
      "  '0.012*\"advancement\" + 0.012*\"technology\" + 0.012*\"know\"'),\n",
      " (2,\n",
      "  '0.074*\"popular\" + 0.074*\"Python\" + 0.074*\"Gensim\" + 0.074*\"modeling\" + '\n",
      "  '0.074*\"similarity\" + 0.074*\"topic\" + 0.074*\"library\" + 0.074*\"document\" + '\n",
      "  '0.011*\"dream\" + 0.011*\"fail\"'),\n",
      " (3,\n",
      "  '0.022*\"dream\" + 0.022*\"fail\" + 0.022*\"year\" + 0.022*\"development\" + '\n",
      "  '0.022*\"big\" + 0.022*\"progress\" + 0.022*\"know\" + 0.022*\"technology\" + '\n",
      "  '0.022*\"advancement\" + 0.022*\"field\"'),\n",
      " (4,\n",
      "  '0.066*\"probabilistic\" + 0.066*\"Latent\" + 0.066*\"model\" + 0.066*\"Dirichlet\" '\n",
      "  '+ 0.066*\"generative\" + 0.066*\"Allocation\" + 0.066*\"big\" + 0.066*\"know\" + '\n",
      "  '0.066*\"fail\" + 0.066*\"dream\"'),\n",
      " (5,\n",
      "  '0.022*\"fail\" + 0.022*\"dream\" + 0.022*\"development\" + 0.022*\"advancement\" + '\n",
      "  '0.022*\"year\" + 0.022*\"know\" + 0.022*\"big\" + 0.022*\"progress\" + '\n",
      "  '0.022*\"technology\" + 0.022*\"field\"')]\n"
     ]
    }
   ],
   "source": [
    "print('LDA Model 6 topics')\n",
    "pprint(lda_model_6.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model 9 topics\n",
      "[(0,\n",
      "  '0.022*\"artificial\" + 0.022*\"big\" + 0.022*\"game\" + 0.022*\"popular\" + '\n",
      "  '0.022*\"generative\" + 0.022*\"model\" + 0.022*\"Gensim\" + 0.022*\"Dirichlet\" + '\n",
      "  '0.022*\"Python\" + 0.022*\"dream\"'),\n",
      " (1,\n",
      "  '0.069*\"development\" + 0.069*\"advancement\" + 0.069*\"field\" + '\n",
      "  '0.069*\"progress\" + 0.069*\"technology\" + 0.069*\"year\" + 0.069*\"fail\" + '\n",
      "  '0.069*\"dream\" + 0.069*\"know\" + 0.069*\"big\"'),\n",
      " (2,\n",
      "  '0.100*\"Latent\" + 0.100*\"Allocation\" + 0.100*\"model\" + 0.100*\"Dirichlet\" + '\n",
      "  '0.100*\"generative\" + 0.100*\"probabilistic\" + 0.010*\"big\" + 0.010*\"game\" + '\n",
      "  '0.010*\"artificial\" + 0.010*\"know\"'),\n",
      " (3,\n",
      "  '0.100*\"language\" + 0.100*\"processing\" + 0.100*\"natural\" + '\n",
      "  '0.100*\"intelligence\" + 0.100*\"subfield\" + 0.100*\"artificial\" + 0.010*\"game\" '\n",
      "  '+ 0.010*\"big\" + 0.010*\"probabilistic\" + 0.010*\"model\"'),\n",
      " (4,\n",
      "  '0.085*\"Python\" + 0.085*\"popular\" + 0.085*\"similarity\" + 0.085*\"library\" + '\n",
      "  '0.085*\"modeling\" + 0.085*\"document\" + 0.085*\"Gensim\" + 0.085*\"topic\" + '\n",
      "  '0.008*\"big\" + 0.008*\"generative\"'),\n",
      " (5,\n",
      "  '0.022*\"language\" + 0.022*\"big\" + 0.022*\"fail\" + 0.022*\"game\" + 0.022*\"know\" '\n",
      "  '+ 0.022*\"popular\" + 0.022*\"generative\" + 0.022*\"Dirichlet\" + '\n",
      "  '0.022*\"probabilistic\" + 0.022*\"dream\"'),\n",
      " (6,\n",
      "  '0.022*\"artificial\" + 0.022*\"big\" + 0.022*\"fail\" + 0.022*\"popular\" + '\n",
      "  '0.022*\"generative\" + 0.022*\"probabilistic\" + 0.022*\"Allocation\" + '\n",
      "  '0.022*\"know\" + 0.022*\"Python\" + 0.022*\"dream\"'),\n",
      " (7,\n",
      "  '0.022*\"game\" + 0.022*\"big\" + 0.022*\"language\" + 0.022*\"dream\" + '\n",
      "  '0.022*\"know\" + 0.022*\"topic\" + 0.022*\"generative\" + 0.022*\"model\" + '\n",
      "  '0.022*\"Dirichlet\" + 0.022*\"popular\"'),\n",
      " (8,\n",
      "  '0.084*\"game\" + 0.044*\"high\" + 0.044*\"bomb\" + 0.044*\"level\" + '\n",
      "  '0.044*\"interface\" + 0.044*\"nice\" + 0.044*\"friendly\" + 0.044*\"amazing\" + '\n",
      "  '0.044*\"FPS\" + 0.044*\"Valorant\"')]\n"
     ]
    }
   ],
   "source": [
    "print('LDA Model 9 topics')\n",
    "pprint(lda_model_9.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign topics to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Topic: [(0, 0.042385425), (1, 0.9151452), (2, 0.0424694)]\n",
      "Document 2 - Topic: [(0, 0.9038851), (1, 0.0481318), (2, 0.0479831)]\n",
      "Document 3 - Topic: [(0, 0.048544057), (1, 0.90280366), (2, 0.04865224)]\n",
      "Document 4 - Topic: [(0, 0.037648547), (1, 0.9246313), (2, 0.037720155)]\n",
      "Document 5 - Topic: [(0, 0.016452452), (1, 0.9673834), (2, 0.01616411)]\n",
      "Document 6 - Topic: [(0, 0.06708779), (1, 0.06682153), (2, 0.86609066)]\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(processed_documents):\n",
    "    print(f\"Document {i+1} - Topic: {lda_model_3.get_document_topics(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Topic: [(0, 0.8958243), (1, 0.020834785), (2, 0.020834608), (3, 0.020835923), (4, 0.020834472), (5, 0.02083592)]\n",
      "Document 2 - Topic: [(0, 0.023827173), (1, 0.88093096), (2, 0.02381016), (3, 0.023810804), (4, 0.02381009), (5, 0.023810804)]\n",
      "Document 3 - Topic: [(0, 0.023809925), (1, 0.02381046), (2, 0.023810344), (3, 0.023811188), (4, 0.88094693), (5, 0.023811188)]\n",
      "Document 4 - Topic: [(0, 0.018542264), (1, 0.018519154), (2, 0.9073803), (3, 0.018519647), (4, 0.018519018), (5, 0.018519647)]\n",
      "Document 5 - Topic: [(0, 0.9602828)]\n",
      "Document 6 - Topic: [(0, 0.03333391), (1, 0.03333468), (2, 0.033334512), (3, 0.033335723), (4, 0.8333255), (5, 0.033335723)]\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(processed_documents):\n",
    "    print(f\"Document {i+1} - Topic: {lda_model_6.get_document_topics(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Topic: [(0, 0.013888932), (1, 0.88888603), (2, 0.013888929), (3, 0.013888929), (4, 0.013888929), (5, 0.013888932), (6, 0.013888932), (7, 0.013888932), (8, 0.013891465)]\n",
      "Document 2 - Topic: [(0, 0.015873048), (1, 0.015873047), (2, 0.015873047), (3, 0.8730147), (4, 0.015873047), (5, 0.015873048), (6, 0.015873048), (7, 0.015873048), (8, 0.015873946)]\n",
      "Document 3 - Topic: [(0, 0.01587305), (1, 0.015873047), (2, 0.87301564), (3, 0.015873047), (4, 0.015873047), (5, 0.01587305), (6, 0.01587305), (7, 0.01587305), (8, 0.015873047)]\n",
      "Document 4 - Topic: [(0, 0.01234571), (1, 0.012345707), (2, 0.012345708), (3, 0.012345708), (4, 0.901233), (5, 0.01234571), (6, 0.01234571), (7, 0.01234571), (8, 0.012346966)]\n",
      "Document 5 - Topic: [(8, 0.95767)]\n",
      "Document 6 - Topic: [(0, 0.02222229), (1, 0.82222164), (2, 0.022222284), (3, 0.022222284), (4, 0.022222284), (5, 0.02222229), (6, 0.02222229), (7, 0.02222229), (8, 0.022222282)]\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(processed_documents):\n",
    "    print(f\"Document {i+1} - Topic: {lda_model_9.get_document_topics(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of topics results in a reduction of the weight assigned to each individual topic. However, certain topics may consistently exhibit a notably larger influence, irrespective of the total number of topics. Evaluating the quality of topics is crucial for enhancing the interpretability of the outcomes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
